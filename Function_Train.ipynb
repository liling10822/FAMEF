{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "func_tag_dic = {\"Data Analysis\":0, \"Data Visualization\":1 , \"Data Preparation\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_corpura = pd.read_csv(\"training_corpus/extended_description.csv\")\n",
    "function_corpura = pd.read_csv(\"training_corpus/function.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URL</th>\n",
       "      <th>contributor</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/GoogleChrome/puppeteer</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>Puppeteer is a Node library which provides a h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>The major contributors of this repository incl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>Integral Regression is initially described in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>We build a 3D pose estimation system based mai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>The Integral Regression is also known as soft-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>409</td>\n",
       "      <td>https://github.com/deepmind/sonnet</td>\n",
       "      <td>Ling Li</td>\n",
       "      <td>Sonnet is a library built on top of TensorFlow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>https://github.com/deepmind/sonnet</td>\n",
       "      <td>Ling Li</td>\n",
       "      <td>It can be used to construct neural networks fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>411</td>\n",
       "      <td>https://github.com/deepmind/sonnet</td>\n",
       "      <td>Ling Li</td>\n",
       "      <td>(un/supervised learning, reinforcement learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>412</td>\n",
       "      <td>https://github.com/deepmind/sonnet</td>\n",
       "      <td>Ling Li</td>\n",
       "      <td>Sonnet does not ship with a training framework...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>413</td>\n",
       "      <td>https://github.com/JaidedAI/EasyOCR</td>\n",
       "      <td>Ling Li</td>\n",
       "      <td>Ready-to-use OCR with 70+ languages supported ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                               URL contributor  \\\n",
       "0             0         https://github.com/GoogleChrome/puppeteer   Allen Mao   \n",
       "1             1  https://github.com/JimmySuen/integral-human-pose   Allen Mao   \n",
       "2             2  https://github.com/JimmySuen/integral-human-pose   Allen Mao   \n",
       "3             3  https://github.com/JimmySuen/integral-human-pose   Allen Mao   \n",
       "4             4  https://github.com/JimmySuen/integral-human-pose   Allen Mao   \n",
       "..          ...                                               ...         ...   \n",
       "409         409                https://github.com/deepmind/sonnet     Ling Li   \n",
       "410         410                https://github.com/deepmind/sonnet     Ling Li   \n",
       "411         411                https://github.com/deepmind/sonnet     Ling Li   \n",
       "412         412                https://github.com/deepmind/sonnet     Ling Li   \n",
       "413         413               https://github.com/JaidedAI/EasyOCR     Ling Li   \n",
       "\n",
       "                                               excerpt  \n",
       "0    Puppeteer is a Node library which provides a h...  \n",
       "1    The major contributors of this repository incl...  \n",
       "2    Integral Regression is initially described in ...  \n",
       "3    We build a 3D pose estimation system based mai...  \n",
       "4    The Integral Regression is also known as soft-...  \n",
       "..                                                 ...  \n",
       "409  Sonnet is a library built on top of TensorFlow...  \n",
       "410  It can be used to construct neural networks fo...  \n",
       "411  (un/supervised learning, reinforcement learnin...  \n",
       "412  Sonnet does not ship with a training framework...  \n",
       "413  Ready-to-use OCR with 70+ languages supported ...  \n",
       "\n",
       "[414 rows x 4 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_corpura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_corpura['label'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/3D-ResNets-PyTorch-README.md',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'If you want to classify your videos or extract video features of them using our pretrained models, use this code.\\n'},\n",
       " 1: {'URL': 'https://github.com/driving-behavior/DBNet',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': \"DBNet is a large-scale driving behavior dataset, which provides large-scale high-quality point clouds scanned by Velodyne lasers, high-resolution videos recorded by dashboard cameras and standard drivers' behaviors (vehicle speed, steering angle) collected by real-time sensors.\"},\n",
       " 2: {'URL': 'https://github.com/hezhangsprinter/DCPDN',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'We propose a new end-to-end single image dehazing method, called Densely Connected Pyramid Dehazing Network (DCPDN), which can jointly learn the transmission map, atmospheric light and dehazing all together'},\n",
       " 3: {'URL': 'https://github.com/hezhangsprinter/DID-MDN',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'We present a novel density-aware multi-stream densely connected convolutional neural network-based algorithm, called DID-MDN, for joint rain density estimation and de-raining.'},\n",
       " 4: {'URL': 'https://github.com/foolwood/DaSiamRPN',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'SiamRPN formulates the task of visual tracking as a task of localization and identification simultaneously, initially described in an CVPR2018 spotlight paper. (Slides at CVPR 2018 Spotlight)'},\n",
       " 5: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/DeepGuidedFilter-README.md',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'Given a reference image pair in high-resolution and low-resolution, our algorithm generates high-resolution target from the low-resolution input. '},\n",
       " 6: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/DeepMVS-README.md',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'DeepMVS is a Deep Convolutional Neural Network which learns to estimate pixel-wise disparity maps from a sequence of an arbitrary number of unordered images with the camera poses already known or estimated.'},\n",
       " 7: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/Detectron-README.md',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': \"Detectron is Facebook AI Research's software system that implements state-of-the-art object detection algorithms, including Mask R-CNN.\"},\n",
       " 8: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/Fiona-README.md',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'Fiona is designed to be simple and dependable. It focuses on reading and writing data in standard Python IO style and relies upon familiar Python types and protocols such as files, dictionaries, mappings, and iterators instead of classes specific to OGR. Fiona can read and write real-world data using multi-layered GIS formats and zipped virtual file systems and integrates readily with other Python GIS packages such as pyproj_, Rtree_, and Shapely_. Fiona is supported only on CPython versions 2.7 and 3.4+.'},\n",
       " 9: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/Flow-Guided-Feature-Aggregation-README.md',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'Flow-Guided Feature Aggregation (FGFA) is initially described in an ICCV 2017 paper. It provides an accurate and end-to-end learning framework for video object detection.'},\n",
       " 10: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/GAN_stability-README.md',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'This repository contains the experiments in the supplementary material for the paper Which Training Methods for GANs do actually Converge?'},\n",
       " 11: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/GANimation-README.md',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'In this work we introduce a novel GAN conditioning scheme based on Action Units (AU) annotations, which describe in a continuous manifold the anatomical facial movements defining a human expression'},\n",
       " 12: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/GPRPy-README.md',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'Open-source Ground Penetrating Radar processing and visualization software.'},\n",
       " 13: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/ICNet-README.md',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'ICNet for Real-Time Semantic Segmentation on High-Resolution Images'},\n",
       " 14: {'URL': 'https://github.com/phoenix104104/LapSRN',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'The Laplacian Pyramid Super-Resolution Network (LapSRN) is a progressive super-resolution model that super-resolves an low-resolution images in a coarse-to-fine Laplacian pyramid framework.'},\n",
       " 15: {'URL': 'https://github.com/JuliaGeo/LibGEOS.jl',\n",
       "  'contributor': 'Ling Li',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'LibGEOS is a package for manipulation and analysis of planar geometric objects'},\n",
       " 16: {'URL': 'https://github.com/ZhouYanzhao/PRM',\n",
       "  'contributor': 'Ling Li',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'The pytorch implementation of Peak Response Mapping (Stimulation and Backprop)'},\n",
       " 17: {'URL': 'https://github.com/OpenGeoVis/PVGeo',\n",
       "  'contributor': 'Ling Li',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'These tools are tailored to data visualization in the geosciences with a heavy focus on structured data sets like 2D or 3D time-varying grids.'},\n",
       " 18: {'URL': 'https://github.com/yulunzhang/RDN',\n",
       "  'contributor': 'Ling Li',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'we propose a novel residual dense network (RDN) to address this problem in image SR.'},\n",
       " 19: {'URL': 'https://github.com/XiaLiPKU/RESCAN',\n",
       "  'contributor': 'Ling Li',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'We propose a novel deep network architecture based on deep convolutional and recurrent neural networks for single image deraining.'},\n",
       " 20: {'URL': 'https://github.com/jiangsutx/SRN-Deblur',\n",
       "  'contributor': 'Ling Li',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'Deep Image Deblurring'},\n",
       " 21: {'URL': 'https://github.com/Toblerity/Shapely',\n",
       "  'contributor': 'Ling Li',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'Shapely is a BSD-licensed Python package for manipulation and analysis of planar geometric objects.'},\n",
       " 22: {'URL': 'https://github.com/ondrolexa/apsg/tree/0.6.1',\n",
       "  'contributor': 'Ling Li',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'analyze and visualize orientational structural geology data.'},\n",
       " 23: {'URL': 'https://github.com/twbs/bootstrap/tree/v4-dev',\n",
       "  'contributor': 'Ling Li',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'Sleek, intuitive, and powerful front-end framework'},\n",
       " 24: {'URL': 'https://github.com/cltk/cltk/tree/master',\n",
       "  'contributor': 'Ling Li',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'compile analysis-friendly corpora;\\ncollect and generate linguistic data;'},\n",
       " 25: {'URL': 'https://github.com/d3/d3',\n",
       "  'contributor': 'Ling Li',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'D3 (or D3.js) is a JavaScript library for visualizing data using web standards.'},\n",
       " 26: {'URL': 'https://github.com/rbgirshick/py-faster-rcnn',\n",
       "  'contributor': 'Ling Li',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'The aim is to improve the cross-domain robustness of object detection, in the screnario where training and test data are drawn from different distributions.'},\n",
       " 27: {'URL': 'https://github.com/empymod',\n",
       "  'contributor': 'Ling Li',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'The electromagnetic modeller empymod can model electric or magnetic responses due to a three-dimensional electric or magnetic source in a layered-earth model with vertical transverse isotropic (VTI) resistivity, VTI electric permittivity, and VTI magnetic permeability, from very low frequencies (DC) to very high frequencies (GPR).'},\n",
       " 28: {'URL': 'https://github.com/facebookresearch/Densepose',\n",
       "  'contributor': 'Ling Li',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'Dense human pose estimation aims at mapping all human pixels of an RGB image to the 3D surface of the human body.'},\n",
       " 29: {'URL': 'facebookresearch-ResNeXt-README.md',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'ResNeXt: Aggregated Residual Transformations for Deep Neural Networks (header)\\nThis repository contains a Torch implementation for the ResNeXt algorithm for image classification.'},\n",
       " 30: {'URL': 'facebookresearch-pyrobot-README.md',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'PyRobot is a light weight, high-level interface which provides hardware independent APIs for robotic manipulation and navigation'},\n",
       " 31: {'URL': 'facebookresearch-wav2letter-README.md',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'The goal of this software is to facilitate research in end-to-end models for speech recognition.'},\n",
       " 32: {'URL': 'gdal-docker-README.md',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'This is an Ubuntu derived image containing the Geospatial Data Abstraction Library (GDAL) compiled with a broad range of drivers.'},\n",
       " 33: {'URL': 'gempy-README.md',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'GemPy is a Python-based, open-source library for implicitly generating 3D structural geological models.\\nIt is capable of constructing complex 3D geological models of folded structures, fault networks and unconformities'},\n",
       " 34: {'URL': 'generator-arcgis-js-app-README.md',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'This is a yeoman generator for ArcGIS API for JavaScript applications.'},\n",
       " 35: {'URL': 'geojson-vt-README.md',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'Created to power GeoJSON in Mapbox GL JS, but can be useful in other visualization platforms like Leaflet and d3, as well as Node.js server applications.'},\n",
       " 36: {'URL': 'geonotebook-README.md',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'GeoNotebook is an application that provides client/server environment with interactive visualization and analysis capabilities using Jupyter, GeoJS and other open source tools.'},\n",
       " 37: {'URL': 'gitbucket-gitbucket-README.md',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'The current version of GitBucket provides many features such as:\\n\\nPublic / Private Git repositories (with http/https and ssh access)\\nGitLFS support\\nRepository viewer including an online file editor\\nIssues, Pull Requests and Wiki for repositories\\nActivity timeline and email notifications\\nAccount and group management with LDAP integration\\na Plug-in system'},\n",
       " 38: {'URL': 'gitfolio-README.md',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'Gitfolio will help you get started with a portfolio website where you could showcase your work + a blog that will help you spread your ideas into real world.'},\n",
       " 39: {'URL': 'gprMax-README.md',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'gprMax was designed for modelling Ground Penetrating Radar (GPR) but can also be used to model electromagnetic wave propagation for many other applications.'},\n",
       " 40: {'URL': 'harismuneer-Ultimate-Facebook-Scraper-README.md',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': \"A bot which scrapes almost everything about a facebook user's profile including\"},\n",
       " 41: {'URL': 'hmr-README.md',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'Images should be tightly cropped, where the height of the person is roughly 150px.\\nOn images that are not tightly cropped, you can runopenpose and supply its output json (run it with --write_json option).'},\n",
       " 42: {'URL': 'hyvr-README.md',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'The Hydrogeological Virtual Reality simulation package (HyVR) is a Python module that helps researchers and practitioners generate subsurface models with multiple scales of heterogeneity that are based on geological concepts.\\nHyVR is able to simulate these bedding parameters and generate spatially distributed parameter fields, including full hydraulic-conductivity tensors.'},\n",
       " 43: {'URL': 'integral-human-pose-README.md',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'We build a 3D pose estimation system based mainly on the Integral Regression, placing second in the ECCV2018 3D Human Pose Estimation Challenge.'},\n",
       " 44: {'URL': 'ipyleaflet-README.md',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'Selecting a basemap for a leaflet map:Loading a geojson map:Making use of leafletjs primitives:Using the splitmap control:Displaying velocity data on the top of a map:Choropleth layer:'},\n",
       " 45: {'URL': 'iter-reason-README.md',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'The available reasoning module is based on convolutions and spatial memory.For simplicity, the released code uses the tensorflow default crop_and_resize operation, rather than the customized one reported in the paper (I find the default one is actually better by ~1%).'},\n",
       " 46: {'URL': 'kosmtik-README.md',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'Very lite but extendable mapping framework to create Mapnik ready maps with OpenStreetMap data (and more).For now, only Carto based projects are supported (with .mml or .yml config), but in the future we hope to plug in MapCSS too.'},\n",
       " 47: {'URL': 'lasio-README.md',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': \"This is a Python 2.7 and 3.3+ package to read and write Log ASCII Standard (LAS) files, used for borehole data such as geophysical, geological, or petrophysical logs. It's compatible with versions 1.2 and 2.0 of the LAS file specification, published by the Canadian Well Logging Society. Support for LAS 3 is being worked on. In principle it is designed to read as many types of LAS files as possible, including ones containing common errors or non-compliant formatting.\"},\n",
       " 48: {'URL': 'map-vectorizer-README.md',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': \"This project aims to automate the manual process of geographic polygon and attribute data extraction from maps (i.e. georectified images) including those from insurance atlases published in the 19th and early 20th centuries. Here is some background on why we're doing this and here is one of the maps we're extracting polygons from. This example map layer shows what these atlases look like once geo-rectified, i.e. geographically normalized.The New York Public Library has hundreds of atlases with tens of thousands of these sheets and there is no way we can extract data manually in a reasonable amount of time.The New York Public Library has hundreds of atlases with tens of thousands of these sheets and there is no way we can extract data manually in a reasonable amount of time.Just so you get an idea, it took NYPL staff coordinating a small army of volunteers three years to produce 170,000 polygons with attributes (from just four of hundreds of atlases at NYPL).Just so you get an idea, it took NYPL staff coordinating a small army of volunteers three years to produce 170,000 polygons with attributes (from just four of hundreds of atlases at NYPL).\"},\n",
       " 49: {'URL': 'mapshaper-README.md',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'Mapshaper is software for editing Shapefile, GeoJSON, TopoJSON, CSV and several other data formats, written in JavaScript.The mapshaper command line program supports essential map making tasks like simplifying shapes, editing attribute data, clipping, erasing, dissolving, filtering and more.The web UI supports interactive simplification, attribute data editing, and running cli commands in a built-in console. Visit the public website at www.mapshaper.org or use the web UI locally via the mapshaper-gui script.'},\n",
       " 50: {'URL': 'microsoft-malmo-README.md',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'MalmoEnv implements an Open AI \"gym\"-like environment in Python without any native code (communicating directly with Java Minecraft). If you only need this functionallity then please see MalmoEnv. This will most likely be the preferred way to develop with Malmo Minecraft going forward.'},\n",
       " 51: {'URL': 'mplleaflet-README.md',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': \"mplleaflet is a Python library that converts a matplotlib plot into a webpage containing a pannable, zoomable Leaflet map. It can also embed the Leaflet map in an IPython notebook. The goal of mplleaflet is to enable use of Python and matplotlib for visualizing geographic data on slippy maps without having to write any Javascript or HTML. You also don't need to worry about choosing the base map content i.e., coastlines, roads, etc. Only one line of code is needed to convert a plot into a web map. mplleaflet.show()\"},\n",
       " 52: {'URL': 'mplstereonet-README.md',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'mplstereonet provides lower-hemisphere equal-area and equal-angle stereonets for matplotlib.'},\n",
       " 53: {'URL': 'neural-motifs-README.md',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'This repository contains data and code for the paper Neural Motifs: Scene Graph Parsing with Global Context (CVPR 2018) For the project page (as well as links to the baseline checkpoints), check out rowanzellers.com/neuralmotifs. If the paper significantly inspires you, we request that you cite our work:'},\n",
       " 54: {'URL': 'neural_renderer-README.md',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'This is code for the paper Neural 3D Mesh Renderer by Hiroharu Kato, Yoshitaka Ushiku, and Tatsuya Harada.'},\n",
       " 55: {'URL': 'nextflow-io-nextflow-README.md',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': \"With the rise of big data, techniques to analyse and run experiments on large datasets are increasingly necessary. Parallelization and distributed computing are the best ways to tackle this problem, but the tools commonly available to the bioinformatics community often lack good support for these techniques, or provide a model that fits badly with the specific requirements in the bioinformatics domain and, most of the time, require the knowledge of complex tools or low-level APIs. Nextflow framework is based on the dataflow programming model, which greatly simplifies writing parallel and distributed pipelines without adding unnecessary complexity and letting you concentrate on the flow of data, i.e. the functional logic of the application/algorithm. It doesn't aim to be another pipeline scripting language yet, but it is built around the idea that the Linux platform is the lingua franca of data science, since it provides many simple command line and scripting tools, which by themselves are powerful, but when chained together facilitate complex data manipulations. In practice, this means that a Nextflow script is defined by composing many different processes. Each process can execute a given bioinformatics tool or scripting language, to which is added the ability to coordinate and synchronize the processes execution by simply specifying their inputs and outputs.\\r\\n\\r\\n\"},\n",
       " 56: {'URL': 'node-qa-masker-README.md',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'This is a NodeJS port of pymasker. It provides a convenient way to produce masks from the Quality Assessment band of Landsat 8 OLI images, as well as MODIS land products.'},\n",
       " 57: {'URL': 'omfvista-README.md',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'A PyVista (and VTK) interface for the Open Mining Format package_ (omf) providing Python 3D visualization and useable mesh data structures for processing datasets in the OMF specification.'},\n",
       " 58: {'URL': 'pose-residual-network-pytorch-README.md',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'This repository contains a PyTorch implementation of the Pose Residual Network (PRN) presented in our ECCV 2018 paper:'},\n",
       " 59: {'URL': 'puppeteer-README.md',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'Most things that you can do manually in the browser can be done using Puppeteer! Here are a few examples to get you started: Generate screenshots and PDFs of pages. Crawl a SPA (Single-Page Application) and generate pre-rendered content (i.e. \"SSR\" (Server-Side Rendering)). Automate form submission, UI testing, keyboard input, etc. Create an up-to-date, automated testing environment. Run your tests directly in the latest version of Chrome using the latest JavaScript and browser features. Capture a timeline trace of your site to help diagnose performance issues. Test Chrome Extensions.'},\n",
       " 60: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/sentinelsat-README.md',\n",
       "  'contributor': 'Yidan Zhang',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'Sentinelsat makes searching, downloading and retrieving the metadata of Sentinel <http://www.esa.int/Our_Activities/Observing_the_Earth/Copernicus/Overview4>_ satellite images from the Copernicus Open Access Hub <https://scihub.copernicus.eu/>_ easy.'},\n",
       " 61: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/sequelize-sequelize-README.md',\n",
       "  'contributor': 'Yidan Zhang',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'It features solid transaction support, relations, eager and lazy loading, read replication and more.'},\n",
       " 62: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/sg2im-README.md',\n",
       "  'contributor': 'Yidan Zhang',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'Below we show some example scene graphs along with images generated from those scene graphs using our model. By modifying the input scene graph we can exercise fine-grained control over the objects in the generated image.'},\n",
       " 63: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/tensorflow-README.md',\n",
       "  'contributor': 'Yidan Zhang',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'TensorFlow is an open source software library for numerical computation using data flow graphs.'},\n",
       " 64: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/tensorflow-magenta-README.md',\n",
       "  'contributor': 'Yidan Zhang',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': \"Magenta is a research project exploring the role of machine learning in the process of creating art and music. Primarily this involves developing new deep learning and reinforcement learning algorithms for generating songs, images, drawings, and other materials. But it's also an exploration in building smart tools and interfaces that allow artists and musicians to extend (not replace!) \"},\n",
       " 65: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/tetgen-README.md',\n",
       "  'contributor': 'Yidan Zhang',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'TetGen generates exact constrained Delaunay tetrahedralization, boundary\\nconforming Delaunay meshes, and Voronoi partitions.\\n\\nTetGen provides various features to generate good quality and adaptive\\ntetrahedral meshes suitable for numerical methods, such as finite element or\\nfinite volume methods.'},\n",
       " 66: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/tilelive-mapnik-README.md',\n",
       "  'contributor': 'Yidan Zhang',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'Renderer backend for tilelive.js that uses node-mapnik to render tiles and grids from a Mapnik XML file. '},\n",
       " 67: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/tilematrix-README.md',\n",
       "  'contributor': 'Yidan Zhang',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'The module is designed to translate between tile indices (zoom, row, column) and map coordinates (e.g. latitute, longitude).\\n\\nTilematrix supports metatiling and tile buffers.'},\n",
       " 68: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/tippecanoe-README.md',\n",
       "  'contributor': 'Yidan Zhang',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'Builds vector tilesets from large (or small) collections of GeoJSON, Geobuf, or CSV features, like these. '},\n",
       " 69: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/two-stream-dyntex-synth-README.md',\n",
       "  'contributor': 'Yidan Zhang',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'Dynamic texture synthesis?'},\n",
       " 70: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/vid2vid-README.md',\n",
       "  'contributor': 'Yidan Zhang',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'Pytorch implementation for high-resolution (e.g., 2048x1024) photorealistic video-to-video translation. It can be used for turning semantic label maps into photo-realistic videos, synthesizing people talking from edge maps, or generating human motions from poses.'},\n",
       " 71: {'URL': 'https://github.com/KnowledgeCaptureAndDiscovery/somef/blob/master/experiments/training_corpus/repos/sentinelsat-README.md',\n",
       "  'contributor': 'Yidan Zhang',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'Vue (pronounced /vjuː/, like view) is a progressive framework for building user interfaces. It is designed from the ground up to be incrementally adoptable, and can easily scale between a library and a framework depending on different use cases.'},\n",
       " 72: {'URL': 'https://github.com/RaRe-Technologies/gensim',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'Gensim is a Python library for topic modelling, document indexing and similarity retrieval with large corpora\\n\\n'},\n",
       " 73: {'URL': 'https://github.com/stanfordnlp/stanza',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'It contains support for running various accurate natural language processing tools on 60+ languages and for accessing the Java Stanford CoreNLP software from Python'},\n",
       " 74: {'URL': 'https://github.com/unagiootoro/ruby-dnn',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'This library supports full connected neural network and convolution neural network and recurrent neural network.'},\n",
       " 75: {'URL': 'https://github.com/ankane/lightgbm',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'high performance gradient boosting - for Ruby'},\n",
       " 76: {'URL': 'https://github.com/SteelBridgeLabs/neo4j-gremlin-bolt',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': 'This project allows the use of the Apache Tinkerpop Java API with the neo4j server using the BOLT protocol.'},\n",
       " 77: {'URL': 'https://github.com/LaurentRDC/scikit-ued',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': \"It aims to be a fully-tested package taking advantage of Python's most recent features.\"},\n",
       " 78: {'URL': 'https://github.com/treeverse/lakeFS',\n",
       "  'contributor': 'Sharad',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'lakeFS is an open source layer that delivers resilience and manageability to object-storage based data lakes.\\nWith lakeFS you can build repeatable, atomic and versioned data lake operations - from complex ETL jobs to data science and analytics.'},\n",
       " 79: {'URL': 'https://github.com/facebookresearch/pytext',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'PyText addresses the often-conflicting requirements of enabling rapid experimentation and of serving models at scale'},\n",
       " 80: {'URL': 'https://github.com/NicolasHug/Surprise',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'Surprise is a Python scikit for building and analyzing recommender systems that deal with explicit rating data.'},\n",
       " 81: {'URL': 'https://github.com/amitt001/delegator.py',\n",
       "  'contributor': 'Pratheek',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'Delegator.py is a simple library for dealing with subprocesses'},\n",
       " 82: {'URL': 'https://github.com/simbody/simbody',\n",
       "  'contributor': 'Yidan Zhang',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'Wide variety of joint, constraint, and force types; easily user-extended.\\nForward, inverse, and mixed dynamics. Motion driven by forces or prescribed motion.\\nContact (Hertz, Hunt and Crossley models).\\nGradient descent, interior point, and global (CMA) optimizers.\\nA variety of numerical integrators with error control.\\nVisualizer, using OpenGL'},\n",
       " 83: {'URL': 'https://github.com/cyverse/atmosphere',\n",
       "  'contributor': 'Yidan Zhang',\n",
       "  'label': 'Data Preparation',\n",
       "  'excerpt': \"Atmosphere is an integrative, private, self-service cloud computing platform designed to provide easy access to preconfigured, frequently used analysis routines, relevant algorithms, and data sets in an available-on-demand environment designed to accommodate computationally and data-intensive bioinformatics tasks.\\nA powerful web client for management and administration of virtual machines\\nA fully RESTful API service for integrating with existing infrastructure components\\nVirtual machine images preconfigured for computational science and iPlant's infrastructure\"},\n",
       " 84: {'URL': 'https://github.com/darwinlau/CASPR',\n",
       "  'contributor': 'Yidan Zhang',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': 'The ability to use the extensive libraries and models of CASPR from the community for your research.\\nThe ability to easily and efficiently add, test and validate your algorithms and models.\\nThe ability to share your research to the community.'},\n",
       " 85: {'URL': 'https://github.com/microsoft/tensorwatch',\n",
       "  'contributor': 'Yidan Zhang',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'It works in Jupyter Notebook to show real-time visualizations of your machine learning training and perform several other key analysis tasks for your models and data.\\nTensorWatch is designed to be flexible and extensible so you can also build your own custom visualizations, UIs, and dashboards. Besides traditional \"what-you-see-is-what-you-log\" approach, it also has a unique capability to execute arbitrary queries against your live ML training process, return a stream as a result of the query and view this stream using your choice of a visualizer (we call this Lazy Logging Mode).'},\n",
       " 86: {'URL': 'https://github.com/CMU-Perceptual-Computing-Lab/openpose',\n",
       "  'contributor': 'Ling Li',\n",
       "  'label': 'Data Analysis',\n",
       "  'excerpt': '2D real-time multi-person keypoint detection:\\n3D real-time single-person keypoint detection\\nCalibration toolbox\\nSingle-person tracking for further speed up or visual smoothing.'},\n",
       " 87: {'URL': 'https://github.com/airbnb/airpal',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': \"Airpal is a web-based, query execution tool which leverages Facebook's PrestoDB to make authoring queries and retrieving results simple for users. Airpal provides the ability to find tables, see metadata, browse sample rows, write and edit queries, then submit queries all in a web interface. Once queries are running, users can track query progress and when finished, get the results back through the browser as a CSV (download it or share it with friends). The results of a query can be used to generate a new Hive table for subsequent analysis, and Airpal maintains a searchable history of all queries run within the tool.\"},\n",
       " 88: {'URL': 'https://github.com/HumbleSoftware/envisionjs',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'Fast interactive HTML5 charts.'},\n",
       " 89: {'URL': 'https://github.com/apache/incubator-echarts',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'Apache ECharts (incubating) is a free, powerful charting and visualization library offering an easy way of adding intuitive, interactive, and highly customizable charts to your commercial products.'},\n",
       " 90: {'URL': 'https://github.com/vega/vega',\n",
       "  'contributor': 'Yi Xie',\n",
       "  'label': 'Data Visualization',\n",
       "  'excerpt': 'Vega is a visualization grammar, a declarative format for creating, saving, and sharing interactive visualization designs. With Vega you can describe data visualizations in a JSON format, and generate interactive views using either HTML5 Canvas or SVG.'}}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_dic = function_corpura.to_dict('index')\n",
    "func_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URL</th>\n",
       "      <th>contributor</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/GoogleChrome/puppeteer</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>Puppeteer is a Node library which provides a h...</td>\n",
       "      <td>Data Preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>The major contributors of this repository incl...</td>\n",
       "      <td>Data Preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>Integral Regression is initially described in ...</td>\n",
       "      <td>Data Preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>We build a 3D pose estimation system based mai...</td>\n",
       "      <td>Data Preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>The Integral Regression is also known as soft-...</td>\n",
       "      <td>Data Preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>https://github.com/simbody/simbody</td>\n",
       "      <td>Yidan Zhang</td>\n",
       "      <td>Simbody is a high-performance, open-source too...</td>\n",
       "      <td>Data Visualization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>400</td>\n",
       "      <td>https://github.com/cyverse/atmosphere</td>\n",
       "      <td>Yidan Zhang</td>\n",
       "      <td>Atmosphere addresses the growing needs for hig...</td>\n",
       "      <td>Data Preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>401</td>\n",
       "      <td>https://github.com/darwinlau/CASPR</td>\n",
       "      <td>Yidan Zhang</td>\n",
       "      <td>The Cable-robot Analysis and Simulation Platfo...</td>\n",
       "      <td>Data Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>402</td>\n",
       "      <td>https://github.com/microsoft/tensorwatch</td>\n",
       "      <td>Yidan Zhang</td>\n",
       "      <td>TensorWatch is a debugging and visualization t...</td>\n",
       "      <td>Data Visualization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>406</td>\n",
       "      <td>https://github.com/CMU-Perceptual-Computing-La...</td>\n",
       "      <td>Ling Li</td>\n",
       "      <td>OpenPose represents the first real-time multi-...</td>\n",
       "      <td>Data Analysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                                URL  \\\n",
       "0             0          https://github.com/GoogleChrome/puppeteer   \n",
       "1             1   https://github.com/JimmySuen/integral-human-pose   \n",
       "2             2   https://github.com/JimmySuen/integral-human-pose   \n",
       "3             3   https://github.com/JimmySuen/integral-human-pose   \n",
       "4             4   https://github.com/JimmySuen/integral-human-pose   \n",
       "..          ...                                                ...   \n",
       "399         399                 https://github.com/simbody/simbody   \n",
       "400         400              https://github.com/cyverse/atmosphere   \n",
       "401         401                 https://github.com/darwinlau/CASPR   \n",
       "402         402           https://github.com/microsoft/tensorwatch   \n",
       "406         406  https://github.com/CMU-Perceptual-Computing-La...   \n",
       "\n",
       "     contributor                                            excerpt  \\\n",
       "0      Allen Mao  Puppeteer is a Node library which provides a h...   \n",
       "1      Allen Mao  The major contributors of this repository incl...   \n",
       "2      Allen Mao  Integral Regression is initially described in ...   \n",
       "3      Allen Mao  We build a 3D pose estimation system based mai...   \n",
       "4      Allen Mao  The Integral Regression is also known as soft-...   \n",
       "..           ...                                                ...   \n",
       "399  Yidan Zhang  Simbody is a high-performance, open-source too...   \n",
       "400  Yidan Zhang  Atmosphere addresses the growing needs for hig...   \n",
       "401  Yidan Zhang  The Cable-robot Analysis and Simulation Platfo...   \n",
       "402  Yidan Zhang  TensorWatch is a debugging and visualization t...   \n",
       "406      Ling Li  OpenPose represents the first real-time multi-...   \n",
       "\n",
       "                  label  \n",
       "0      Data Preparation  \n",
       "1      Data Preparation  \n",
       "2      Data Preparation  \n",
       "3      Data Preparation  \n",
       "4      Data Preparation  \n",
       "..                  ...  \n",
       "399  Data Visualization  \n",
       "400    Data Preparation  \n",
       "401       Data Analysis  \n",
       "402  Data Visualization  \n",
       "406       Data Analysis  \n",
       "\n",
       "[331 rows x 5 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "count=0\n",
    "drop = []\n",
    "for index_dec,row_dec in description_corpura.iterrows():\n",
    "    u = row_dec['URL'].split('/')\n",
    "    for i in func_dic:\n",
    "        if re.search(u[-1],func_dic[i]['URL']) is not None:\n",
    "            #print(u[-1],func_dic[i]['URL'])\n",
    "            description_corpura.loc[index_dec,'label'] = func_dic[i]['label']\n",
    "    if description_corpura.loc[index_dec,'label'] is None:\n",
    "        drop.append(index_dec)\n",
    "dic = description_corpura.to_dict('index')  \n",
    "url= []\n",
    "for i in drop:\n",
    "    url.append(dic[i]['URL'])\n",
    "description_corpura= description_corpura.drop(drop,axis = 0,inplace = False)\n",
    "description_corpura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URL</th>\n",
       "      <th>contributor</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Data Analysis</th>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Preparation</th>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Visualization</th>\n",
       "      <td>139</td>\n",
       "      <td>139</td>\n",
       "      <td>139</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Unnamed: 0  URL  contributor  excerpt\n",
       "label                                                    \n",
       "Data Analysis              117  117          117      117\n",
       "Data Preparation            75   75           75       75\n",
       "Data Visualization         139  139          139      139"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = description_corpura.groupby('label').count()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "for tag in func_tag_dic:\n",
    "    func_corpura.replace(tag,func_tag_dic[tag], inplace=True)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#Encounter some errors when we downloaded treebank, so use ssl\n",
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context=ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "#----------Download End-------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate,StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score,recall_score,roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "stop_words = stopwords.words('english')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_func, Y_func = description_corpura[\"excerpt\"], description_corpura[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     Data Analysis       0.61      0.41      0.49        34\n",
      "  Data Preparation       0.83      0.23      0.36        22\n",
      "Data Visualization       0.44      0.89      0.59        27\n",
      "\n",
      "          accuracy                           0.52        83\n",
      "         macro avg       0.63      0.51      0.48        83\n",
      "      weighted avg       0.61      0.52      0.49        83\n",
      "\n",
      "null accuracy: 40.96%\n",
      "accuracy score: 51.81%\n",
      "model is 10.84% more accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 51.81%\n",
      "Precision score : 0.6288244766505636\n",
      "Recall score  : 0.5093087740146564\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(CountVectorizer(), LogisticRegression(penalty='l2',multi_class='multinomial',solver = 'lbfgs'))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n",
    "#print(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37313433 0.58208955 0.5        0.42424242 0.46153846]\n",
      "Mean accuracy of CV: 0.4682009532755802\n",
      "Description ROC\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle=True)\n",
    "\n",
    "cv_results = cross_validate(pipeline, X_func, Y_func, cv=5,scoring='accuracy')\n",
    "print(cv_results['test_score'])\n",
    "print('Mean accuracy of CV:',cv_results['test_score'].mean())\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "i = 0\n",
    "print('Description ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) TfidfVectorizer + LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     Data Analysis       0.66      0.76      0.70        25\n",
      "  Data Preparation       1.00      0.18      0.30        17\n",
      "Data Visualization       0.67      0.83      0.74        41\n",
      "\n",
      "          accuracy                           0.67        83\n",
      "         macro avg       0.77      0.59      0.58        83\n",
      "      weighted avg       0.73      0.67      0.64        83\n",
      "\n",
      "null accuracy: 49.40%\n",
      "accuracy score: 67.47%\n",
      "model is 18.07% more accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 67.47%\n",
      "Precision score : 0.7739463601532567\n",
      "Recall score  : 0.5885796269727402\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(TfidfVectorizer(), LogisticRegression(solver='liblinear'))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n",
    "#print(y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) TfidfVectorizer + NaiveBayes¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     Data Analysis       0.78      0.39      0.52        36\n",
      "  Data Preparation       1.00      0.28      0.43        18\n",
      "Data Visualization       0.47      0.97      0.63        29\n",
      "\n",
      "          accuracy                           0.57        83\n",
      "         macro avg       0.75      0.54      0.53        83\n",
      "      weighted avg       0.72      0.57      0.54        83\n",
      "\n",
      "null accuracy: 43.37%\n",
      "accuracy score: 56.63%\n",
      "model is 13.25% more accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 56.63%\n",
      "Precision score : 0.7481481481481481\n",
      "Recall score  : 0.5440613026819924\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Level TF-IDF + NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5180722891566265\n"
     ]
    }
   ],
   "source": [
    "train_x, valid_x, train_y,valid_y = train_test_split(X_func, Y_func)\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=50)\n",
    "tfidf_vect.fit(description_corpura[\"excerpt\"])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return accuracy_score(predictions, valid_y)\n",
    "\n",
    "accuracy = train_model(MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print (accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) TfidfVectorizer + Perceptron¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     Data Analysis       0.50      0.44      0.47        25\n",
      "  Data Preparation       0.80      0.40      0.53        20\n",
      "Data Visualization       0.61      0.82      0.70        38\n",
      "\n",
      "          accuracy                           0.60        83\n",
      "         macro avg       0.64      0.55      0.57        83\n",
      "      weighted avg       0.62      0.60      0.59        83\n",
      "\n",
      "null accuracy: 45.78%\n",
      "accuracy score: 60.24%\n",
      "model is 14.46% more accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 60.24%\n",
      "Precision score : 0.6359477124183006\n",
      "Recall score  : 0.5519298245614035\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = make_pipeline(TfidfVectorizer(), Perceptron())\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "#y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer + K neighboors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     Data Analysis       0.61      0.83      0.70        30\n",
      "  Data Preparation       0.44      0.57      0.50        14\n",
      "Data Visualization       0.79      0.49      0.60        39\n",
      "\n",
      "          accuracy                           0.63        83\n",
      "         macro avg       0.62      0.63      0.60        83\n",
      "      weighted avg       0.67      0.63      0.62        83\n",
      "\n",
      "null accuracy: 46.99%\n",
      "accuracy score: 62.65%\n",
      "model is 15.66% more accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 62.65%\n",
      "Precision score : 0.6152890695573622\n",
      "Recall score  : 0.6306471306471306\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipeline = make_pipeline(TfidfVectorizer(), KNeighborsClassifier(n_neighbors=2))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "#y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     Data Analysis       0.48      0.62      0.54        26\n",
      "  Data Preparation       1.00      0.26      0.42        19\n",
      "Data Visualization       0.58      0.68      0.63        38\n",
      "\n",
      "          accuracy                           0.57        83\n",
      "         macro avg       0.69      0.52      0.53        83\n",
      "      weighted avg       0.65      0.57      0.55        83\n",
      "\n",
      "null accuracy: 45.78%\n",
      "accuracy score: 56.63%\n",
      "model is 10.84% more accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 56.63%\n",
      "Precision score : 0.6875420875420876\n",
      "Recall score  : 0.5209176788124156\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipeline = make_pipeline(TfidfVectorizer(), RandomForestClassifier())\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "#y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_stopwords(x):\n",
    "    tokens = nltk.word_tokenize(x)\n",
    "    tokens=[i for i in tokens if i not in stop_words]\n",
    "    res=' '.join(tokens)\n",
    "    \n",
    "    return res\n",
    "\n",
    "#del ext_desc['Unnamed: 0']\n",
    "description_corpura['excerpt'] = description_corpura['excerpt'].apply(remove_stopwords)\n",
    "X_func, Y_func = description_corpura[\"excerpt\"], description_corpura[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     Data Analysis       0.58      0.53      0.55        34\n",
      "  Data Preparation       0.47      0.47      0.47        17\n",
      "Data Visualization       0.51      0.56      0.54        32\n",
      "\n",
      "          accuracy                           0.53        83\n",
      "         macro avg       0.52      0.52      0.52        83\n",
      "      weighted avg       0.53      0.53      0.53        83\n",
      "\n",
      "null accuracy: 40.96%\n",
      "accuracy score: 53.01%\n",
      "model is 12.05% more accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 53.01%\n",
      "Precision score : 0.5218397036233848\n",
      "Recall score  : 0.5208333333333334\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = make_pipeline(TfidfVectorizer(), Perceptron())\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "#y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_corpura['char_count'] = description_corpura['excerpt'].apply(len)\n",
    "description_corpura['word_count'] = description_corpura['excerpt'].apply(lambda x: len(x.split()))\n",
    "description_corpura['word_density'] = description_corpura['char_count'] / (description_corpura['word_count']+1)\n",
    "description_corpura['punctuation_count'] = description_corpura['excerpt'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "description_corpura['title_word_count'] = description_corpura['excerpt'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "description_corpura['upper_case_word_count'] = description_corpura['excerpt'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_family = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' : ['RB','RBR','RBS','WRB']\n",
    "}\n",
    "\n",
    "# function to check and get the part of speech tag count of a words in a given sentence\n",
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt\n",
    "\n",
    "description_corpura['noun_count'] = description_corpura['excerpt'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "description_corpura['verb_count'] = description_corpura['excerpt'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "description_corpura['adj_count'] = description_corpura['excerpt'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "description_corpura['adv_count'] = description_corpura['excerpt'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "description_corpura['pron_count'] = description_corpura['excerpt'].apply(lambda x: check_pos_tag(x, 'pron'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URL</th>\n",
       "      <th>contributor</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/GoogleChrome/puppeteer</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>Puppeteer Node library provides high-level API...</td>\n",
       "      <td>Data Preparation</td>\n",
       "      <td>179</td>\n",
       "      <td>26</td>\n",
       "      <td>6.629630</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>The major contributors repository include Xiao...</td>\n",
       "      <td>Data Preparation</td>\n",
       "      <td>105</td>\n",
       "      <td>20</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>Integral Regression initially described ECCV 2...</td>\n",
       "      <td>Data Preparation</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>5.384615</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>We build 3D pose estimation system based mainl...</td>\n",
       "      <td>Data Preparation</td>\n",
       "      <td>333</td>\n",
       "      <td>50</td>\n",
       "      <td>6.529412</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>The Integral Regression also known soft-argmax...</td>\n",
       "      <td>Data Preparation</td>\n",
       "      <td>168</td>\n",
       "      <td>27</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>https://github.com/simbody/simbody</td>\n",
       "      <td>Yidan Zhang</td>\n",
       "      <td>Simbody high-performance , open-source toolkit...</td>\n",
       "      <td>Data Visualization</td>\n",
       "      <td>344</td>\n",
       "      <td>43</td>\n",
       "      <td>7.818182</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>400</td>\n",
       "      <td>https://github.com/cyverse/atmosphere</td>\n",
       "      <td>Yidan Zhang</td>\n",
       "      <td>Atmosphere addresses growing needs highly conf...</td>\n",
       "      <td>Data Preparation</td>\n",
       "      <td>131</td>\n",
       "      <td>15</td>\n",
       "      <td>8.187500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>401</td>\n",
       "      <td>https://github.com/darwinlau/CASPR</td>\n",
       "      <td>Yidan Zhang</td>\n",
       "      <td>The Cable-robot Analysis Simulation Platform R...</td>\n",
       "      <td>Data Analysis</td>\n",
       "      <td>179</td>\n",
       "      <td>22</td>\n",
       "      <td>7.782609</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>402</td>\n",
       "      <td>https://github.com/microsoft/tensorwatch</td>\n",
       "      <td>Yidan Zhang</td>\n",
       "      <td>TensorWatch debugging visualization tool desig...</td>\n",
       "      <td>Data Visualization</td>\n",
       "      <td>122</td>\n",
       "      <td>15</td>\n",
       "      <td>7.625000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>406</td>\n",
       "      <td>https://github.com/CMU-Perceptual-Computing-La...</td>\n",
       "      <td>Ling Li</td>\n",
       "      <td>OpenPose represents first real-time multi-pers...</td>\n",
       "      <td>Data Analysis</td>\n",
       "      <td>152</td>\n",
       "      <td>24</td>\n",
       "      <td>6.080000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                                URL  \\\n",
       "0             0          https://github.com/GoogleChrome/puppeteer   \n",
       "1             1   https://github.com/JimmySuen/integral-human-pose   \n",
       "2             2   https://github.com/JimmySuen/integral-human-pose   \n",
       "3             3   https://github.com/JimmySuen/integral-human-pose   \n",
       "4             4   https://github.com/JimmySuen/integral-human-pose   \n",
       "..          ...                                                ...   \n",
       "399         399                 https://github.com/simbody/simbody   \n",
       "400         400              https://github.com/cyverse/atmosphere   \n",
       "401         401                 https://github.com/darwinlau/CASPR   \n",
       "402         402           https://github.com/microsoft/tensorwatch   \n",
       "406         406  https://github.com/CMU-Perceptual-Computing-La...   \n",
       "\n",
       "     contributor                                            excerpt  \\\n",
       "0      Allen Mao  Puppeteer Node library provides high-level API...   \n",
       "1      Allen Mao  The major contributors repository include Xiao...   \n",
       "2      Allen Mao  Integral Regression initially described ECCV 2...   \n",
       "3      Allen Mao  We build 3D pose estimation system based mainl...   \n",
       "4      Allen Mao  The Integral Regression also known soft-argmax...   \n",
       "..           ...                                                ...   \n",
       "399  Yidan Zhang  Simbody high-performance , open-source toolkit...   \n",
       "400  Yidan Zhang  Atmosphere addresses growing needs highly conf...   \n",
       "401  Yidan Zhang  The Cable-robot Analysis Simulation Platform R...   \n",
       "402  Yidan Zhang  TensorWatch debugging visualization tool desig...   \n",
       "406      Ling Li  OpenPose represents first real-time multi-pers...   \n",
       "\n",
       "                  label  char_count  word_count  word_density  \\\n",
       "0      Data Preparation         179          26      6.629630   \n",
       "1      Data Preparation         105          20      5.000000   \n",
       "2      Data Preparation          70          12      5.384615   \n",
       "3      Data Preparation         333          50      6.529412   \n",
       "4      Data Preparation         168          27      6.000000   \n",
       "..                  ...         ...         ...           ...   \n",
       "399  Data Visualization         344          43      7.818182   \n",
       "400    Data Preparation         131          15      8.187500   \n",
       "401       Data Analysis         179          22      7.782609   \n",
       "402  Data Visualization         122          15      7.625000   \n",
       "406       Data Analysis         152          24      6.080000   \n",
       "\n",
       "     punctuation_count  title_word_count  upper_case_word_count  noun_count  \\\n",
       "0                    7                 8                      1           0   \n",
       "1                    5                11                      0           0   \n",
       "2                    4                 3                      1           0   \n",
       "3                   11                17                      5           0   \n",
       "4                    7                 6                      0           0   \n",
       "..                 ...               ...                    ...         ...   \n",
       "399                 13                 1                      0           0   \n",
       "400                  1                 1                      0           0   \n",
       "401                  6                 5                      2           0   \n",
       "402                  2                 2                      0           0   \n",
       "406                  7                 0                      0           0   \n",
       "\n",
       "     verb_count  adj_count  adv_count  pron_count  \n",
       "0             0          0          0           0  \n",
       "1             0          0          0           0  \n",
       "2             0          0          0           0  \n",
       "3             0          0          0           0  \n",
       "4             0          0          0           0  \n",
       "..          ...        ...        ...         ...  \n",
       "399           0          0          0           0  \n",
       "400           0          0          0           0  \n",
       "401           0          0          0           0  \n",
       "402           0          0          0           0  \n",
       "406           0          0          0           0  \n",
       "\n",
       "[331 rows x 16 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_corpura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'naive_bayes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-fa6ed2eb0430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnaive_bayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisplay_accuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'naive_bayes' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(CountVectorizer(),naive_bayes.MultinomialNB())\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n",
    "#print(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
