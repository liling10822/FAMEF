{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "func_tag_dic = {\"Data Analysis\":0, \"Data Visualization\":1 , \"Data Preparation\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_corpura = pd.read_csv(\"training_corpus/extended_description.csv\")\n",
    "function_corpura = pd.read_csv(\"training_corpus/function.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URL</th>\n",
       "      <th>contributor</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/GoogleChrome/puppeteer</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>Puppeteer is a Node library which provides a h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>The major contributors of this repository incl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>Integral Regression is initially described in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>We build a 3D pose estimation system based mai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>The Integral Regression is also known as soft-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>409</td>\n",
       "      <td>https://github.com/deepmind/sonnet</td>\n",
       "      <td>Ling Li</td>\n",
       "      <td>Sonnet is a library built on top of TensorFlow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>https://github.com/deepmind/sonnet</td>\n",
       "      <td>Ling Li</td>\n",
       "      <td>It can be used to construct neural networks fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>411</td>\n",
       "      <td>https://github.com/deepmind/sonnet</td>\n",
       "      <td>Ling Li</td>\n",
       "      <td>(un/supervised learning, reinforcement learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>412</td>\n",
       "      <td>https://github.com/deepmind/sonnet</td>\n",
       "      <td>Ling Li</td>\n",
       "      <td>Sonnet does not ship with a training framework...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>413</td>\n",
       "      <td>https://github.com/JaidedAI/EasyOCR</td>\n",
       "      <td>Ling Li</td>\n",
       "      <td>Ready-to-use OCR with 70+ languages supported ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                               URL contributor  \\\n",
       "0             0         https://github.com/GoogleChrome/puppeteer   Allen Mao   \n",
       "1             1  https://github.com/JimmySuen/integral-human-pose   Allen Mao   \n",
       "2             2  https://github.com/JimmySuen/integral-human-pose   Allen Mao   \n",
       "3             3  https://github.com/JimmySuen/integral-human-pose   Allen Mao   \n",
       "4             4  https://github.com/JimmySuen/integral-human-pose   Allen Mao   \n",
       "..          ...                                               ...         ...   \n",
       "409         409                https://github.com/deepmind/sonnet     Ling Li   \n",
       "410         410                https://github.com/deepmind/sonnet     Ling Li   \n",
       "411         411                https://github.com/deepmind/sonnet     Ling Li   \n",
       "412         412                https://github.com/deepmind/sonnet     Ling Li   \n",
       "413         413               https://github.com/JaidedAI/EasyOCR     Ling Li   \n",
       "\n",
       "                                               excerpt  \n",
       "0    Puppeteer is a Node library which provides a h...  \n",
       "1    The major contributors of this repository incl...  \n",
       "2    Integral Regression is initially described in ...  \n",
       "3    We build a 3D pose estimation system based mai...  \n",
       "4    The Integral Regression is also known as soft-...  \n",
       "..                                                 ...  \n",
       "409  Sonnet is a library built on top of TensorFlow...  \n",
       "410  It can be used to construct neural networks fo...  \n",
       "411  (un/supervised learning, reinforcement learnin...  \n",
       "412  Sonnet does not ship with a training framework...  \n",
       "413  Ready-to-use OCR with 70+ languages supported ...  \n",
       "\n",
       "[414 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_corpura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_corpura['label'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_dic = function_corpura.to_dict('index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URL</th>\n",
       "      <th>contributor</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/GoogleChrome/puppeteer</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>Puppeteer is a Node library which provides a h...</td>\n",
       "      <td>Data Preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>The major contributors of this repository incl...</td>\n",
       "      <td>Data Preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>Integral Regression is initially described in ...</td>\n",
       "      <td>Data Preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>We build a 3D pose estimation system based mai...</td>\n",
       "      <td>Data Preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>The Integral Regression is also known as soft-...</td>\n",
       "      <td>Data Preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>https://github.com/simbody/simbody</td>\n",
       "      <td>Yidan Zhang</td>\n",
       "      <td>Simbody is a high-performance, open-source too...</td>\n",
       "      <td>Data Visualization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>400</td>\n",
       "      <td>https://github.com/cyverse/atmosphere</td>\n",
       "      <td>Yidan Zhang</td>\n",
       "      <td>Atmosphere addresses the growing needs for hig...</td>\n",
       "      <td>Data Preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>401</td>\n",
       "      <td>https://github.com/darwinlau/CASPR</td>\n",
       "      <td>Yidan Zhang</td>\n",
       "      <td>The Cable-robot Analysis and Simulation Platfo...</td>\n",
       "      <td>Data Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>402</td>\n",
       "      <td>https://github.com/microsoft/tensorwatch</td>\n",
       "      <td>Yidan Zhang</td>\n",
       "      <td>TensorWatch is a debugging and visualization t...</td>\n",
       "      <td>Data Visualization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>406</td>\n",
       "      <td>https://github.com/CMU-Perceptual-Computing-La...</td>\n",
       "      <td>Ling Li</td>\n",
       "      <td>OpenPose represents the first real-time multi-...</td>\n",
       "      <td>Data Analysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                                URL  \\\n",
       "0             0          https://github.com/GoogleChrome/puppeteer   \n",
       "1             1   https://github.com/JimmySuen/integral-human-pose   \n",
       "2             2   https://github.com/JimmySuen/integral-human-pose   \n",
       "3             3   https://github.com/JimmySuen/integral-human-pose   \n",
       "4             4   https://github.com/JimmySuen/integral-human-pose   \n",
       "..          ...                                                ...   \n",
       "399         399                 https://github.com/simbody/simbody   \n",
       "400         400              https://github.com/cyverse/atmosphere   \n",
       "401         401                 https://github.com/darwinlau/CASPR   \n",
       "402         402           https://github.com/microsoft/tensorwatch   \n",
       "406         406  https://github.com/CMU-Perceptual-Computing-La...   \n",
       "\n",
       "     contributor                                            excerpt  \\\n",
       "0      Allen Mao  Puppeteer is a Node library which provides a h...   \n",
       "1      Allen Mao  The major contributors of this repository incl...   \n",
       "2      Allen Mao  Integral Regression is initially described in ...   \n",
       "3      Allen Mao  We build a 3D pose estimation system based mai...   \n",
       "4      Allen Mao  The Integral Regression is also known as soft-...   \n",
       "..           ...                                                ...   \n",
       "399  Yidan Zhang  Simbody is a high-performance, open-source too...   \n",
       "400  Yidan Zhang  Atmosphere addresses the growing needs for hig...   \n",
       "401  Yidan Zhang  The Cable-robot Analysis and Simulation Platfo...   \n",
       "402  Yidan Zhang  TensorWatch is a debugging and visualization t...   \n",
       "406      Ling Li  OpenPose represents the first real-time multi-...   \n",
       "\n",
       "                  label  \n",
       "0      Data Preparation  \n",
       "1      Data Preparation  \n",
       "2      Data Preparation  \n",
       "3      Data Preparation  \n",
       "4      Data Preparation  \n",
       "..                  ...  \n",
       "399  Data Visualization  \n",
       "400    Data Preparation  \n",
       "401       Data Analysis  \n",
       "402  Data Visualization  \n",
       "406       Data Analysis  \n",
       "\n",
       "[331 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "count=0\n",
    "drop = []\n",
    "for index_dec,row_dec in description_corpura.iterrows():\n",
    "    u = row_dec['URL'].split('/')\n",
    "    for i in func_dic:\n",
    "        if re.search(u[-1],func_dic[i]['URL']) is not None:\n",
    "            #print(u[-1],func_dic[i]['URL'])\n",
    "            description_corpura.loc[index_dec,'label'] = func_dic[i]['label']\n",
    "    if description_corpura.loc[index_dec,'label'] is None:\n",
    "        drop.append(index_dec)\n",
    "dic = description_corpura.to_dict('index')  \n",
    "url= []\n",
    "for i in drop:\n",
    "    url.append(dic[i]['URL'])\n",
    "description_corpura= description_corpura.drop(drop,axis = 0,inplace = False)\n",
    "description_corpura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URL</th>\n",
       "      <th>contributor</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Data Analysis</th>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Preparation</th>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Visualization</th>\n",
       "      <td>139</td>\n",
       "      <td>139</td>\n",
       "      <td>139</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Unnamed: 0  URL  contributor  excerpt\n",
       "label                                                    \n",
       "Data Analysis              117  117          117      117\n",
       "Data Preparation            75   75           75       75\n",
       "Data Visualization         139  139          139      139"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = description_corpura.groupby('label').count()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "for tag in func_tag_dic:\n",
    "    description_corpura.replace(tag,func_tag_dic[tag], inplace=True)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#Encounter some errors when we downloaded treebank, so use ssl\n",
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context=ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "#----------Download End-------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate,StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score,recall_score,roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "stop_words = stopwords.words('english')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_func, Y_func = description_corpura[\"excerpt\"], description_corpura[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.67      0.75        33\n",
      "           1       0.67      0.87      0.76        38\n",
      "           2       0.62      0.42      0.50        12\n",
      "\n",
      "    accuracy                           0.72        83\n",
      "   macro avg       0.71      0.65      0.67        83\n",
      "weighted avg       0.74      0.72      0.72        83\n",
      "\n",
      "null accuracy: 45.78%\n",
      "accuracy score: 72.29%\n",
      "model is 26.51% more accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 72.29%\n",
      "Precision score : 0.7148744113029828\n",
      "Recall score  : 0.6505847953216375\n",
      "\n",
      "\n",
      "[0.37313433 0.58208955 0.5        0.42424242 0.46153846]\n",
      "Mean accuracy of CV: 0.4682009532755802\n",
      "Function ROC\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-67c8d67ba43a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Function ROC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mprobas_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;31m# Compute ROC curve and area under the curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"integer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1951\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m             \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1594\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1595\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[1;32m   1596\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1552\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m         )\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1652\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 1654\u001b[0;31m                     \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1655\u001b[0m                     \u001b[0;34m\"is no longer supported, see \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                     \u001b[0;34m\"https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"\u001b[0m  \u001b[0;31m# noqa:E501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(CountVectorizer(), LogisticRegression(penalty='l2',multi_class='multinomial',solver = 'lbfgs'))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n",
    "#print(y_pred_class)\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle=True)\n",
    "\n",
    "cv_results = cross_validate(pipeline, X_func, Y_func, cv=5,scoring='accuracy')\n",
    "print(cv_results['test_score'])\n",
    "print('Mean accuracy of CV:',cv_results['test_score'].mean())\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "i = 0\n",
    "print('Function ROC')\n",
    "for train, test in cv.split(X_func, Y_func):\n",
    "    probas_ = pipeline.fit(X_func[train], Y_func[train]).predict_proba(X_func[test])\n",
    "    # Compute ROC curve and area under the curve\n",
    "    fpr, tpr, thresholds = roc_curve(Y_func[test], probas_[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i+=1\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Description Classification')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for train, test in cv.split(X_func, Y_func):\n",
    "    probas_ = pipeline.fit(X_func[train], Y_func[train]).predict_proba(X_func[test])\n",
    "    precision, recall, _ = precision_recall_curve(Y_func[test], probas_[:,1])\n",
    "\n",
    "    plt.step(recall, precision, alpha=0.2,\n",
    "             where='post', label=f'average precision={average_precision_score(Y_func[test], probas_[:,1])}')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "plt.title('Description Precision-Recall curve'.format(\n",
    "          average_precision_score(Y_func[test], probas_[:,1])))\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) TfidfVectorizer + LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.55      0.57        29\n",
      "           1       0.60      0.82      0.70        39\n",
      "           2       1.00      0.20      0.33        15\n",
      "\n",
      "    accuracy                           0.61        83\n",
      "   macro avg       0.73      0.52      0.53        83\n",
      "weighted avg       0.67      0.61      0.59        83\n",
      "\n",
      "null accuracy: 46.99%\n",
      "accuracy score: 61.45%\n",
      "model is 14.46% more accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 61.45%\n",
      "Precision score : 0.7321220591660843\n",
      "Recall score  : 0.5240789861479517\n",
      "\n",
      "\n",
      "[0.44776119 0.59701493 0.54545455 0.51515152 0.50769231]\n",
      "Mean accuracy of CV: 0.5226148975402707\n",
      "Function ROC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(TfidfVectorizer(), LogisticRegression(solver='liblinear'))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n",
    "#print(y_pred_class)\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle=True)\n",
    "\n",
    "cv_results = cross_validate(pipeline, X_func, Y_func, cv=5,scoring='accuracy')\n",
    "print(cv_results['test_score'])\n",
    "print('Mean accuracy of CV:',cv_results['test_score'].mean())\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "i = 0\n",
    "print('Function ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) TfidfVectorizer + NaiveBayes¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.59      0.62        32\n",
      "           1       0.61      0.82      0.70        34\n",
      "           2       1.00      0.47      0.64        17\n",
      "\n",
      "    accuracy                           0.66        83\n",
      "   macro avg       0.75      0.63      0.65        83\n",
      "weighted avg       0.71      0.66      0.66        83\n",
      "\n",
      "null accuracy: 40.96%\n",
      "accuracy score: 66.27%\n",
      "model is 25.30% more accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 66.27%\n",
      "Precision score : 0.7546226886556721\n",
      "Recall score  : 0.6292892156862745\n",
      "\n",
      "\n",
      "[0.40298507 0.64179104 0.56060606 0.53030303 0.50769231]\n",
      "Mean accuracy of CV: 0.5286755036008767\n",
      "Function ROC\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle=True)\n",
    "\n",
    "cv_results = cross_validate(pipeline, X_func, Y_func, cv=5,scoring='accuracy')\n",
    "print(cv_results['test_score'])\n",
    "print('Mean accuracy of CV:',cv_results['test_score'].mean())\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "i = 0\n",
    "print('Function ROC')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Level TF-IDF + NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46987951807228917\n"
     ]
    }
   ],
   "source": [
    "train_x, valid_x, train_y,valid_y = train_test_split(X_func, Y_func)\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=50)\n",
    "tfidf_vect.fit(description_corpura[\"excerpt\"])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return accuracy_score(predictions, valid_y)\n",
    "\n",
    "accuracy = train_model(MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print (accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) TfidfVectorizer + Perceptron¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71        32\n",
      "           1       0.67      0.88      0.76        32\n",
      "           2       0.73      0.42      0.53        19\n",
      "\n",
      "    accuracy                           0.70        83\n",
      "   macro avg       0.71      0.66      0.67        83\n",
      "weighted avg       0.71      0.70      0.69        83\n",
      "\n",
      "null accuracy: 38.55%\n",
      "accuracy score: 69.88%\n",
      "model is 31.33% more accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 69.88%\n",
      "Precision score : 0.709090909090909\n",
      "Recall score  : 0.6611842105263158\n",
      "\n",
      "\n",
      "[0.40298507 0.58208955 0.62121212 0.40909091 0.49230769]\n",
      "Mean accuracy of CV: 0.5015370698952789\n",
      "Function ROC\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = make_pipeline(TfidfVectorizer(), Perceptron())\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "#y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle=True)\n",
    "\n",
    "cv_results = cross_validate(pipeline, X_func, Y_func, cv=5,scoring='accuracy')\n",
    "print(cv_results['test_score'])\n",
    "print('Mean accuracy of CV:',cv_results['test_score'].mean())\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "i = 0\n",
    "print('Function ROC')\n",
    "with open('function.sk', 'wb') as model_file:\n",
    "  pickle.dump(pipeline, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50        24\n",
      "           1       0.51      0.81      0.62        36\n",
      "           2       1.00      0.09      0.16        23\n",
      "\n",
      "    accuracy                           0.52        83\n",
      "   macro avg       0.67      0.46      0.43        83\n",
      "weighted avg       0.64      0.52      0.46        83\n",
      "\n",
      "null accuracy: 43.37%\n",
      "accuracy score: 51.81%\n",
      "model is 8.43% more accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 51.81%\n",
      "Precision score : 0.6695906432748538\n",
      "Recall score  : 0.464170692431562\n",
      "\n",
      "\n",
      "[0.37313433 0.49253731 0.40909091 0.5        0.38461538]\n",
      "Mean accuracy of CV: 0.4318755870994678\n",
      "Function ROC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipeline = make_pipeline(TfidfVectorizer(), RandomForestClassifier())\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "#y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle=True)\n",
    "\n",
    "cv_results = cross_validate(pipeline, X_func, Y_func, cv=5,scoring='accuracy')\n",
    "print(cv_results['test_score'])\n",
    "print('Mean accuracy of CV:',cv_results['test_score'].mean())\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "i = 0\n",
    "print('Function ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_stopwords(x):\n",
    "    tokens = nltk.word_tokenize(x)\n",
    "    tokens=[i for i in tokens if i not in stop_words]\n",
    "    res=' '.join(tokens)\n",
    "    \n",
    "    return res\n",
    "\n",
    "#del ext_desc['Unnamed: 0']\n",
    "description_corpura['excerpt'] = description_corpura['excerpt'].apply(remove_stopwords)\n",
    "X_func, Y_func = description_corpura[\"excerpt\"], description_corpura[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.52      0.53        29\n",
      "           1       0.65      0.67      0.66        36\n",
      "           2       0.61      0.61      0.61        18\n",
      "\n",
      "    accuracy                           0.60        83\n",
      "   macro avg       0.60      0.60      0.60        83\n",
      "weighted avg       0.60      0.60      0.60        83\n",
      "\n",
      "null accuracy: 43.37%\n",
      "accuracy score: 60.24%\n",
      "model is 16.87% more accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 60.24%\n",
      "Precision score : 0.5984913484913484\n",
      "Recall score  : 0.5983397190293742\n",
      "\n",
      "\n",
      "[0.41791045 0.55223881 0.57575758 0.46969697 0.46153846]\n",
      "Mean accuracy of CV: 0.4954284521448701\n",
      "Function ROC\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = make_pipeline(TfidfVectorizer(), Perceptron())\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "#y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "cv = StratifiedKFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "cv_results = cross_validate(pipeline, X_func, Y_func, cv=5,scoring='accuracy')\n",
    "print(cv_results['test_score'])\n",
    "print('Mean accuracy of CV:',cv_results['test_score'].mean())\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "i = 0\n",
    "print('Function ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_corpura['char_count'] = description_corpura['excerpt'].apply(len)\n",
    "description_corpura['word_count'] = description_corpura['excerpt'].apply(lambda x: len(x.split()))\n",
    "description_corpura['word_density'] = description_corpura['char_count'] / (description_corpura['word_count']+1)\n",
    "description_corpura['punctuation_count'] = description_corpura['excerpt'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "description_corpura['title_word_count'] = description_corpura['excerpt'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "description_corpura['upper_case_word_count'] = description_corpura['excerpt'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_family = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' : ['RB','RBR','RBS','WRB']\n",
    "}\n",
    "\n",
    "# function to check and get the part of speech tag count of a words in a given sentence\n",
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt\n",
    "\n",
    "description_corpura['noun_count'] = description_corpura['excerpt'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "description_corpura['verb_count'] = description_corpura['excerpt'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "description_corpura['adj_count'] = description_corpura['excerpt'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "description_corpura['adv_count'] = description_corpura['excerpt'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "description_corpura['pron_count'] = description_corpura['excerpt'].apply(lambda x: check_pos_tag(x, 'pron'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URL</th>\n",
       "      <th>contributor</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://github.com/GoogleChrome/puppeteer</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>Puppeteer Node library provides high-level API...</td>\n",
       "      <td>Data Preparation</td>\n",
       "      <td>179</td>\n",
       "      <td>26</td>\n",
       "      <td>6.629630</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>The major contributors repository include Xiao...</td>\n",
       "      <td>Data Preparation</td>\n",
       "      <td>105</td>\n",
       "      <td>20</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>Integral Regression initially described ECCV 2...</td>\n",
       "      <td>Data Preparation</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>5.384615</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>We build 3D pose estimation system based mainl...</td>\n",
       "      <td>Data Preparation</td>\n",
       "      <td>333</td>\n",
       "      <td>50</td>\n",
       "      <td>6.529412</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://github.com/JimmySuen/integral-human-pose</td>\n",
       "      <td>Allen Mao</td>\n",
       "      <td>The Integral Regression also known soft-argmax...</td>\n",
       "      <td>Data Preparation</td>\n",
       "      <td>168</td>\n",
       "      <td>27</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>https://github.com/simbody/simbody</td>\n",
       "      <td>Yidan Zhang</td>\n",
       "      <td>Simbody high-performance , open-source toolkit...</td>\n",
       "      <td>Data Visualization</td>\n",
       "      <td>344</td>\n",
       "      <td>43</td>\n",
       "      <td>7.818182</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>400</td>\n",
       "      <td>https://github.com/cyverse/atmosphere</td>\n",
       "      <td>Yidan Zhang</td>\n",
       "      <td>Atmosphere addresses growing needs highly conf...</td>\n",
       "      <td>Data Preparation</td>\n",
       "      <td>131</td>\n",
       "      <td>15</td>\n",
       "      <td>8.187500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>401</td>\n",
       "      <td>https://github.com/darwinlau/CASPR</td>\n",
       "      <td>Yidan Zhang</td>\n",
       "      <td>The Cable-robot Analysis Simulation Platform R...</td>\n",
       "      <td>Data Analysis</td>\n",
       "      <td>179</td>\n",
       "      <td>22</td>\n",
       "      <td>7.782609</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>402</td>\n",
       "      <td>https://github.com/microsoft/tensorwatch</td>\n",
       "      <td>Yidan Zhang</td>\n",
       "      <td>TensorWatch debugging visualization tool desig...</td>\n",
       "      <td>Data Visualization</td>\n",
       "      <td>122</td>\n",
       "      <td>15</td>\n",
       "      <td>7.625000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>406</td>\n",
       "      <td>https://github.com/CMU-Perceptual-Computing-La...</td>\n",
       "      <td>Ling Li</td>\n",
       "      <td>OpenPose represents first real-time multi-pers...</td>\n",
       "      <td>Data Analysis</td>\n",
       "      <td>152</td>\n",
       "      <td>24</td>\n",
       "      <td>6.080000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                                URL  \\\n",
       "0             0          https://github.com/GoogleChrome/puppeteer   \n",
       "1             1   https://github.com/JimmySuen/integral-human-pose   \n",
       "2             2   https://github.com/JimmySuen/integral-human-pose   \n",
       "3             3   https://github.com/JimmySuen/integral-human-pose   \n",
       "4             4   https://github.com/JimmySuen/integral-human-pose   \n",
       "..          ...                                                ...   \n",
       "399         399                 https://github.com/simbody/simbody   \n",
       "400         400              https://github.com/cyverse/atmosphere   \n",
       "401         401                 https://github.com/darwinlau/CASPR   \n",
       "402         402           https://github.com/microsoft/tensorwatch   \n",
       "406         406  https://github.com/CMU-Perceptual-Computing-La...   \n",
       "\n",
       "     contributor                                            excerpt  \\\n",
       "0      Allen Mao  Puppeteer Node library provides high-level API...   \n",
       "1      Allen Mao  The major contributors repository include Xiao...   \n",
       "2      Allen Mao  Integral Regression initially described ECCV 2...   \n",
       "3      Allen Mao  We build 3D pose estimation system based mainl...   \n",
       "4      Allen Mao  The Integral Regression also known soft-argmax...   \n",
       "..           ...                                                ...   \n",
       "399  Yidan Zhang  Simbody high-performance , open-source toolkit...   \n",
       "400  Yidan Zhang  Atmosphere addresses growing needs highly conf...   \n",
       "401  Yidan Zhang  The Cable-robot Analysis Simulation Platform R...   \n",
       "402  Yidan Zhang  TensorWatch debugging visualization tool desig...   \n",
       "406      Ling Li  OpenPose represents first real-time multi-pers...   \n",
       "\n",
       "                  label  char_count  word_count  word_density  \\\n",
       "0      Data Preparation         179          26      6.629630   \n",
       "1      Data Preparation         105          20      5.000000   \n",
       "2      Data Preparation          70          12      5.384615   \n",
       "3      Data Preparation         333          50      6.529412   \n",
       "4      Data Preparation         168          27      6.000000   \n",
       "..                  ...         ...         ...           ...   \n",
       "399  Data Visualization         344          43      7.818182   \n",
       "400    Data Preparation         131          15      8.187500   \n",
       "401       Data Analysis         179          22      7.782609   \n",
       "402  Data Visualization         122          15      7.625000   \n",
       "406       Data Analysis         152          24      6.080000   \n",
       "\n",
       "     punctuation_count  title_word_count  upper_case_word_count  noun_count  \\\n",
       "0                    7                 8                      1           0   \n",
       "1                    5                11                      0           0   \n",
       "2                    4                 3                      1           0   \n",
       "3                   11                17                      5           0   \n",
       "4                    7                 6                      0           0   \n",
       "..                 ...               ...                    ...         ...   \n",
       "399                 13                 1                      0           0   \n",
       "400                  1                 1                      0           0   \n",
       "401                  6                 5                      2           0   \n",
       "402                  2                 2                      0           0   \n",
       "406                  7                 0                      0           0   \n",
       "\n",
       "     verb_count  adj_count  adv_count  pron_count  \n",
       "0             0          0          0           0  \n",
       "1             0          0          0           0  \n",
       "2             0          0          0           0  \n",
       "3             0          0          0           0  \n",
       "4             0          0          0           0  \n",
       "..          ...        ...        ...         ...  \n",
       "399           0          0          0           0  \n",
       "400           0          0          0           0  \n",
       "401           0          0          0           0  \n",
       "402           0          0          0           0  \n",
       "406           0          0          0           0  \n",
       "\n",
       "[331 rows x 16 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_corpura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'naive_bayes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-fa6ed2eb0430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnaive_bayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdisplay_accuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'naive_bayes' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(CountVectorizer(),naive_bayes.MultinomialNB())\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n",
    "#print(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
