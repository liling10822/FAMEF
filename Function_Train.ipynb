{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "func_tag_dic = {\"Data Analysis\":0, \"Data Visualization\":1 , \"Data Preparation\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_corpura = pd.read_csv(\"function.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>contributor</th>\n",
       "      <th>label</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/KnowledgeCaptureAndDiscover...</td>\n",
       "      <td>Pratheek</td>\n",
       "      <td>Data Preparation</td>\n",
       "      <td>If you want to classify your videos or extract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/driving-behavior/DBNet</td>\n",
       "      <td>Pratheek</td>\n",
       "      <td>Data Preparation</td>\n",
       "      <td>DBNet is a large-scale driving behavior datase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/hezhangsprinter/DCPDN</td>\n",
       "      <td>Pratheek</td>\n",
       "      <td>Data Preparation</td>\n",
       "      <td>We propose a new end-to-end single image dehaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/hezhangsprinter/DID-MDN</td>\n",
       "      <td>Pratheek</td>\n",
       "      <td>Data Analysis</td>\n",
       "      <td>We present a novel density-aware multi-stream ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://github.com/foolwood/DaSiamRPN</td>\n",
       "      <td>Pratheek</td>\n",
       "      <td>Data Visualization</td>\n",
       "      <td>SiamRPN formulates the task of visual tracking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>https://github.com/CMU-Perceptual-Computing-La...</td>\n",
       "      <td>Ling Li</td>\n",
       "      <td>Data Analysis</td>\n",
       "      <td>2D real-time multi-person keypoint detection:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>https://github.com/airbnb/airpal</td>\n",
       "      <td>Yi Xie</td>\n",
       "      <td>Data Visualization</td>\n",
       "      <td>Airpal is a web-based, query execution tool wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>https://github.com/HumbleSoftware/envisionjs</td>\n",
       "      <td>Yi Xie</td>\n",
       "      <td>Data Visualization</td>\n",
       "      <td>Fast interactive HTML5 charts.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>https://github.com/apache/incubator-echarts</td>\n",
       "      <td>Yi Xie</td>\n",
       "      <td>Data Visualization</td>\n",
       "      <td>Apache ECharts (incubating) is a free, powerfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>https://github.com/vega/vega</td>\n",
       "      <td>Yi Xie</td>\n",
       "      <td>Data Visualization</td>\n",
       "      <td>Vega is a visualization grammar, a declarative...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  URL contributor  \\\n",
       "0   https://github.com/KnowledgeCaptureAndDiscover...    Pratheek   \n",
       "1           https://github.com/driving-behavior/DBNet    Pratheek   \n",
       "2            https://github.com/hezhangsprinter/DCPDN    Pratheek   \n",
       "3          https://github.com/hezhangsprinter/DID-MDN    Pratheek   \n",
       "4               https://github.com/foolwood/DaSiamRPN    Pratheek   \n",
       "..                                                ...         ...   \n",
       "86  https://github.com/CMU-Perceptual-Computing-La...     Ling Li   \n",
       "87                   https://github.com/airbnb/airpal      Yi Xie   \n",
       "88       https://github.com/HumbleSoftware/envisionjs      Yi Xie   \n",
       "89        https://github.com/apache/incubator-echarts      Yi Xie   \n",
       "90                       https://github.com/vega/vega      Yi Xie   \n",
       "\n",
       "                 label                                            excerpt  \n",
       "0     Data Preparation  If you want to classify your videos or extract...  \n",
       "1     Data Preparation  DBNet is a large-scale driving behavior datase...  \n",
       "2     Data Preparation  We propose a new end-to-end single image dehaz...  \n",
       "3        Data Analysis  We present a novel density-aware multi-stream ...  \n",
       "4   Data Visualization  SiamRPN formulates the task of visual tracking...  \n",
       "..                 ...                                                ...  \n",
       "86       Data Analysis  2D real-time multi-person keypoint detection:\\...  \n",
       "87  Data Visualization  Airpal is a web-based, query execution tool wh...  \n",
       "88  Data Visualization                     Fast interactive HTML5 charts.  \n",
       "89  Data Visualization  Apache ECharts (incubating) is a free, powerfu...  \n",
       "90  Data Visualization  Vega is a visualization grammar, a declarative...  \n",
       "\n",
       "[91 rows x 4 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_corpura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>contributor</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Data Analysis</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Preparation</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data Visualization</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    URL  contributor  excerpt\n",
       "label                                        \n",
       "Data Analysis        33           33       33\n",
       "Data Preparation     28           28       28\n",
       "Data Visualization   30           30       30"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = func_corpura.groupby('label').count()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "for tag in func_tag_dic:\n",
    "    func_corpura.replace(tag,func_tag_dic[tag], inplace=True)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#Encounter some errors when we downloaded treebank, so use ssl\n",
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context=ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "nltk.download('stopwords')\n",
    "#----------Download End-------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate,StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score,recall_score,roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "stop_words = stopwords.words('english')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_func, Y_func = func_corpura[\"excerpt\"], func_corpura[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.86      0.52         7\n",
      "           1       0.67      0.29      0.40         7\n",
      "           2       0.50      0.22      0.31         9\n",
      "\n",
      "    accuracy                           0.43        23\n",
      "   macro avg       0.51      0.46      0.41        23\n",
      "weighted avg       0.51      0.43      0.40        23\n",
      "\n",
      "null accuracy: 39.13%\n",
      "accuracy score: 43.48%\n",
      "model is 4.35% more accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 43.48%\n",
      "Precision score : 0.5138888888888888\n",
      "Recall score  : 0.45502645502645506\n",
      "\n",
      "\n",
      "[0 0 1 0 2 0 0 2 1 0 0 0 2 0 0 0 0 0 0 2 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(CountVectorizer(), LogisticRegression(penalty='l2',multi_class='multinomial',solver = 'lbfgs'))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n",
    "print(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63157895 0.36842105 0.57894737 0.47058824 0.41176471]\n",
      "Mean accuracy of CV: 0.49226006191950467\n",
      "Description ROC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv = StratifiedKFold(n_splits = 5, shuffle=True)\n",
    "\n",
    "cv_results = cross_validate(pipeline, X_func, Y_func, cv=5,scoring='accuracy')\n",
    "print(cv_results['test_score'])\n",
    "print('Mean accuracy of CV:',cv_results['test_score'].mean())\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "i = 0\n",
    "print('Description ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) TfidfVectorizer + LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      1.00      0.48         6\n",
      "           1       1.00      0.22      0.36         9\n",
      "           2       1.00      0.25      0.40         8\n",
      "\n",
      "    accuracy                           0.43        23\n",
      "   macro avg       0.77      0.49      0.41        23\n",
      "weighted avg       0.82      0.43      0.41        23\n",
      "\n",
      "null accuracy: 39.13%\n",
      "accuracy score: 43.48%\n",
      "model is 4.35% more accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 43.48%\n",
      "Precision score : 0.7719298245614036\n",
      "Recall score  : 0.49074074074074076\n",
      "\n",
      "\n",
      "[1 0 0 0 0 0 1 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = make_pipeline(TfidfVectorizer(), LogisticRegression(solver = 'liblinear'))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n",
    "print(y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) TfidfVectorizer + NaiveBayesÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      1.00      0.32         4\n",
      "           1       1.00      0.11      0.20         9\n",
      "           2       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.22        23\n",
      "   macro avg       0.40      0.37      0.17        23\n",
      "weighted avg       0.42      0.22      0.13        23\n",
      "\n",
      "null accuracy: 43.48%\n",
      "accuracy score: 21.74%\n",
      "model is 21.74% less accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 21.74%\n",
      "Precision score : 0.3968253968253968\n",
      "Recall score  : 0.3703703703703704\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) TfidfVectorizer + PerceptronÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.80      0.53         5\n",
      "           1       0.50      0.33      0.40         9\n",
      "           2       0.29      0.22      0.25         9\n",
      "\n",
      "    accuracy                           0.39        23\n",
      "   macro avg       0.40      0.45      0.39        23\n",
      "weighted avg       0.39      0.39      0.37        23\n",
      "\n",
      "null accuracy: 39.13%\n",
      "accuracy score: 39.13%\n",
      "model is exactly as accurate as null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 39.13%\n",
      "Precision score : 0.3952380952380952\n",
      "Recall score  : 0.4518518518518519\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = make_pipeline(TfidfVectorizer(), Perceptron())\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "#y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K neighboors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.67      0.50         9\n",
      "           1       0.17      0.33      0.22         3\n",
      "           2       0.50      0.09      0.15        11\n",
      "\n",
      "    accuracy                           0.35        23\n",
      "   macro avg       0.36      0.36      0.29        23\n",
      "weighted avg       0.42      0.35      0.30        23\n",
      "\n",
      "null accuracy: 47.83%\n",
      "accuracy score: 34.78%\n",
      "model is 13.04% less accurate than null accuracy\n",
      "\n",
      "\n",
      "accuracy score: 34.78%\n",
      "Precision score : 0.35555555555555557\n",
      "Recall score  : 0.3636363636363636\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipeline = make_pipeline(TfidfVectorizer(), KNeighborsClassifier(n_neighbors=3))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_func, Y_func)\n",
    "\n",
    "\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print('accuracy score: %s' % '{:.2%}'.format(score))\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print('null accuracy: %s' % '{:.2%}'.format(null_accuracy))\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print('model is %s more accurate than null accuracy' % '{:.2%}'.format(difference))\n",
    "    elif difference < 0:\n",
    "        print('model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference)))\n",
    "    elif difference == 0:\n",
    "        print('model is exactly as accurate as null accuracy')\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_class = pipeline.predict(X_test)\n",
    "#y_pred_vals = pipeline.predict_proba(X_test)\n",
    "results_df = pd.DataFrame({\"x_test\": X_test,  \"y_TF_pred\": y_pred_class, \"y_actual\": Y_test})\n",
    "#print(results_df)\n",
    "#print(confusion_matrix(y_test, y_pred_class))\n",
    "#print('-' * 75 + '\\nClassification Report\\n')\n",
    "print(classification_report(Y_test, y_pred_class))\n",
    "\n",
    "display_accuracy_difference(Y_test, y_pred_class)\n",
    "print('\\n')\n",
    "display_accuracy_score(Y_test, y_pred_class)\n",
    "print('Precision score :',precision_score(Y_test, y_pred_class,average='macro'))\n",
    "print('Recall score  :',recall_score(Y_test, y_pred_class,average='macro'))\n",
    "\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
